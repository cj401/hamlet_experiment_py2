\section{Background}

The conventional Hierarchical Dirichlet Process Hidden Markov Model
(HDP-HMM) \cite{teh2006hierarchical} 
is a prior distribution on the transition matrix of a Hidden Markov
Model with a countably infinite state space.  The rows of the
infinite matrix are coupled through their dependence on a common, discrete base measure,
itself drawn from a Dirichlet Process (DP).
The hierarchical structure ensures that, despite the infinite state
space, a common set of destination states will be reachable with high probability
from each source state.  The generative process for the HDP-HMM is the following:

Each of a countably infinite set of states, indexed by $j$, has parameters,
$\theta_j$, drawn from a base measure, $H$.  A top-level
set of state weights, $\bbeta = (\beta_1, \beta_2, \dots)$, is drawn from a stick-breaking
process ($\mathsf{GEM}$) with concentration parameter $\gamma > 0$.
\begin{equation}
\theta_j \stackrel{i.i.d.}{\sim} H \qquad \bbeta \sim \mathsf{GEM}(\gamma)
\end{equation}
The actual transition distribution, $\bpi_j$, from state $j$,
is drawn from a DP with concentration $\alpha$ and base measure $\bbeta$:
\begin{equation}
  \label{eq:1}
  \bpi_j \stackrel{i.i.d}{\sim} DP(\alpha \bbeta) \qquad j = 1, 2, \dots
\end{equation}
The hidden state sequence is then generated according to the $\pi_j$.
Let $z_t$ be the index of the chain's state at time $t$.  Then we have
\begin{equation}
  \label{eq:4}
  z_t \given z_{t-1}, \bpi_{z_{t-1}} \sim \bpi_{z_{t-1}} \qquad t = 1, 2, \dots, T
\end{equation}
where $T$ is the length of the data sequence.  Finally, the emission distribution 
for state $j$ is a function of $\theta_j$, so that we have
\begin{equation}
  \label{eq:5}
  y_t \given z_{t}, \theta_{z_t} \sim F(\theta_{z_t})
\end{equation}

A shortcoming of this model is that the generative process does not
take into account the fact that the set of source states is the same
as the set of destination states: that is, the distribution $\bpi_j$
has an element which corresponds to state $j$.  Put another way, there
is no special treatment of the diagonal of the transition matrix, so
that self-transitions are no more likely {\it a priori} than
transitions to any other state.  The Sticky HDP-HMM \cite{fox2008hdp}
addresses this issue by adding an extra mass at location $j$ to the base
measure of the DP that generates $\bpi_j$.  That is, \eqref{eq:1} is replaced by
\begin{equation}
  \label{eq:6}
  \bpi_j \sim DP(\alpha\bbeta + \kappa \delta_j).
\end{equation}
An alternative approach that treats self-transitions as special 
is the HDP Hidden Semi-Markov Model (HDP-HSMM)
\cite{johnson2013bayesian}, wherein state duration distributions are modeled
separately, and ordinary self-transitions are ruled out.  In both the
Sticky HDP-HMM and the HDP-HSMM, auxiliary latent variables are introduced to simplify
conditional posterior distributions and facilitate Gibbs sampling.
However, while both of these models have the ability to privilege
self-transitions, they contain no notion of
similarity for pairs of states that are not identical: 
in both cases, when the transition matrix
is integrated out, the prior probability of
transitioning to state $j'$ depends only on the top-level stick
weight associated with state $j'$, and not on the identity or
parameters of the previous state $j$.
