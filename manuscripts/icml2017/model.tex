\section{An HDP-HMM With Local Transitions}
\label{sec:model}
We wish to add to the transition model the concept of a transition to
a ``nearby'' state, where transitions between states $j$ and $j'$ are
more likely {\em a priori} to the extent that they are ``nearby'' in
some similarity space.  In order to accomplish this, we first
consider an alternative construction of the transition distributions,
based on the Normalized Gamma Process representation of the DP
\cite{ishwaran2002exact, ferguson1973bayesian}.


\subsection{A Normalized Gamma Process representation of the HDP-HMM}
\label{sec:normalized-gamma}

The Dirichlet Process is an instance of a normalized completely random measure
\cite{kingman1967completely, ferguson1973bayesian},
which can be defined as $G = \sum_{k=1}^{\infty} \tilde{\pi}_k \delta_{\theta_k}$, where 
\begin{align}
  \pi_{k} \stackrel{ind}{\sim} \Gamm{\alpha \beta_{k}}{1} \quad T =
  \sum_{k=1}^{\infty} \pi_{k} \quad
  \tilde{\pi}_{k} = \frac{\pi_{k}}{T} \label{eq:20},
\end{align}
$\delta_{\theta}$ is a measure assigning 1 to any set containing $\theta$ and
0 to any other set, and subject to the constraint 
that $\sum_{k\geq 1} \beta_{k} = 1$ and $0 < \alpha < \infty$.  It
has previously been shown \cite{ferguson1973bayesian, paisley2012discrete, favaro2013mcmc}
that the normalization constant $T$ is positive and finite almost
surely, and that $G$ is distributed as a DP
with base measure $G_0 = \sum_{k=1}^{\infty} \beta_{k} \delta_{\theta_{k}}$.
If we draw $\bbeta = (\beta_1, \beta_2, \dots)$ from the
$\GEM{\gamma}$ stick-breaking process, draw an
i.i.d. sequence of $\theta_k$ from a base measure $H$, and then draw an i.i.d.
series of random measures, $\{G_j\}, j = 1, 2, \dots$ from the above process
then this defines a Hierarchical Dirichlet Process (HDP).  If each $G_j$
is associated with the hidden states of an HMM, $\bpi$ is the infinite
matrix where entry $\pi_{jj'}$ is
the $j'$th mass associated with the $j$th random measure, and
$T_j$ is the sum of row $j$, we obtain the prior for the HDP-HMM, where
\begin{align}
  \label{eq:50}
  p(z_t \given z_{t-1}, \bpi) = \tilde{\pi}_{z_{t-1}z_t} = \pi_{jj'} / T_j
\end{align}

\subsection{Promoting ``Local'' Transitions}
\label{sec:prom-local-trans}

In the preceding formulation, the rows of the transition matrix 
are independent conditioned on the top-level measure.  Our goal is to relax this
assumption, in order to incorporate possible prior knowledge
that certain pairs of states are more likely than others to
produce large transition weights between them (in both directions).  
We accomplish this by associating each latent state, $j$, with a location,
$\ell_j$ in some space $\Omega$, introducing a ``similarity function'', $\phi: \Omega
\times \Omega \to (0,1]$, which depending on the application 
may or may not depend on the other state parameters,
$\theta_j$, and scaling each element,
$\pi_{jj'}$, by $\phi_{jj'} = \phi(\ell_{j}, \ell_{j'})$.
Letting $\bell = (\ell_1, \ell_2, \dots)$, we can then replace \eqref{eq:20} by
\begin{align}
\begin{split}
  &\pi_{jj'} \given \bbeta, \bell \sim \Gamm{\alpha
    \beta_{j'}}{1} \quad
  T_j = \sum_{j'=1}^{\infty} \pi_{jj'}\phi_{jj'} \\
&\tilde{\pi}_{jj'} = \frac{\pi_{jj'}\phi_{jj'}}{T_j} \quad p(z_t \given
z_{t-1}, \bpi, \bell) = \tilde{\pi}_{z_{t-1}z_t}.
\end{split}
\end{align}
Since the $\phi_{jj'}$ are assumed positive and
bounded above, each $T_j$ is bounded below by $\pi_{j1}$
and above by $\sum_{j'} \pi_{jj'}$, both of which are positive and
finite $a.s.$ (as in the original HDP). The prior means of the
unnormalized transition distributions, $\bpi_j$ are then 
proportional (for each $j$) to $\alpha\bbeta\bphi_{j}$ where $\bphi_j
= (\phi_{j1}, \phi_{j2}, \dots)$.

The distribution of the latent state sequence
$\bz$ given $\bpi$ and $\bell$ is now
\begin{align}
\begin{split}
  p(\bz \given \bpi, \bell) &= \prod_{t=1}^T \pi_{z_{t-1}z_t}
  \phi_{z_{t-1}z_t} T_{z_{t-1}}^{-n_{j\cdot}} \\
  &= \prod_{j=1}^\infty T_j^{-1} \prod_{j'=1}^{\infty}
  \pi_{jj'}^{n_{jj'}} \phi_{jj'}^{n_{jj'}}
\end{split}
\end{align}
where $n_{jj'} = \sum_{t=1}^T I(z_{t-1} = j, z_{t} = j')$ is the
number of transitions from state $j$ to state $j'$ in the sequence
$\bz$ and $n_{j\cdot} = \sum_{j'} n_{jj'}$ is the total number of
visits to state $j$.  Due to the fact that $T_j$ is a sum over products of
$\pi_{jj'}$ and $\phi_{jj'}$ terms, the posterior for
$\bpi$ is no longer a DP.  However, conditional conjugacy can be
restored by a data-augmentation process with a natural interpretation, 
which is described next.

\subsection{The HDP-HMM-LT as the Marginalization of
a Markov Jump Process with ``Failed'' Transitions}
\label{sec:mjp-ft}

In this section, we define a stochastic process that we call the
Markov Jump Process with Failed Transitions (MJP-FT), from which we obtain the HDP-HMM-LT
by marginalizing over some of the variables.  By reinstating these
auxiliary variables, we obtain a simple Gibbs sampling algorithm over
the full MJP-FT, which can be used to sample from the marginal
posterior of the variables used by the HDP-HMM-LT.

Let $\bbeta$, $\bpi$, $\bell$ and $T_j, j = 1, 2, \dots$ be defined as
in the last section. Consider a continuous-time Markov Process over the states $j = 1, 2,
\dots$, and suppose that if the process makes a jump to state 
$z_{t}$ at time $\tau_t$, the next jump, which is to state $z_{t+1}$, occurs at
time $\tau_t + \tilde{u}_t$, where $\tilde{u}_{t} \sim \Exp{\sum_{j'} \pi_{jj'}}$,
and $p(z_{t+1} = j' \given z_{t} = j) \propto
\pi_{jj'}$, independent of $\tilde{u}_t$.  Note that in this
formulation, unlike in standard formulations of Markov Jump Processes,
we are assuming that self-jumps are possible.

If we only observe the jump sequence $\bz$ and not the holding times, 
$\tilde{u}_t$, this is an ordinary Markov chain with transition matrix row-proportional to
$\bpi$.  If we do not observe the jumps themselves, but
instead an observation is generated once per jump from a distribution that depends
on the state being jumped to, then we have an ordinary HMM whose
transition matrix is obtained by normalizing $\bpi$; that
is, we have the HDP-HMM.

We modify this process as follows.  
Suppose that each jump attempt from state $j$ to state $j'$ has a
chance of failing, which is an increasing function of the ``distance''
between the states.  In particular, let the success probability be
$\phi_{jj'}$.  Assuming successes are independent, then the rate of 
successful jumps from $j$ to $j'$ is $\pi_{jj'}\phi_{jj'}$, and the 
corresponding rate of unsuccessful jump
attempts is $\pi_{jj'}(1-\phi_{jj'})$ (see Supplementary Materials for
a proof).  The probability that the first successful jump is to
state $j'$ (that is, that $z_{t+1} = j'$) 
is proportional to the rate of successful jump attempts to $j'$, which
is $\pi_{jj'}\phi_{jj'}$.  Conditioned on $z_t$, the holding time, $\tilde{u}_{t}$, is
independent of $z_{t+1}$ and is distributed $\mathsf{Exp}(T_{z_t})$.  The
total time spent in state $j$ given that it is visited $n_{j}$ times,
is then
\begin{equation}
u_j \given \bz, \bpi, \btheta \stackrel{ind}{\sim} \Gamm{n_{j\cdot}}{T_j}
\end{equation}
During this period there will be $q_{jj'}$
unsuccessful attempts to jump to state $j'$, where $q_{jj'}$ is distributed $\Pois{u_j
\pi_{jj'}(1 - \phi_{jj'})}$.  Incorporating
$\bu = \{u_j\}$ and $\bQ = (q_{jj'})$ as augmented data simplifies 
the likelihood for $\bpi$, yielding
\begin{align}
  p(\bz, &\bu, \bQ \given \bpi) =  p(\bz \given \bpi) p(\bu \given
  \bz, \bpi) p(\bQ \given \bu, \bpi)
\end{align}
where dependence on $\bell$ has been omitted for conciseness.  After
grouping terms, this is
\begin{align}
\begin{split}
\label{eq:joint-likelihood}
\prod_{j} \prod_{j'} \pi_{jj'}^{n_{jj'} + q_{jj'}} \phi_{jj'}^{n_{jj'}}
  (1-\phi_{jj'})^{q_{jj'}}
  e^{-\pi_{jj'}u_j}
\end{split}
\end{align}
Conveniently, the $T_j$ have canceled, and the exponential terms involving
$\pi_{jj'}$ and $\phi_{jj'}$ in the Gamma and Poisson distributions of
$u_{j}$ and $q_{jj'}$ combine to cause $\phi_{jj'}$ to vanish.

\subsection{Sticky and Semi-Markov Generalizations}
\label{sec:an-hsmm-modification}

We note that it is trivial to employ the local transition property of
the HDP-HMM-LT together with the Sticky property of the Sticky
HDP-HMM \cite{fox2008hdp}, or the non-geometric duration distributions of the
HDP-HSMM \cite{johnson2013bayesian}, should an application call for
additional prior weight to be placed on self-transitions.  In the
former case, no changes to inference are needed; one can simply add the
the extra mass $\kappa$ to the shape parameter of the Gamma prior on
the $\pi_{jj}$, and employ the same auxiliary variable method used by
\citeauthor{fox2008hdp} to distinguish ``Sticky'' from ``regular'' self-transitions.
For the semi-Markov case, we can simply fix the diagonal
elements of $\bpi$ to zero, and allow $D_t$ observations to be
emitted $i.i.d.$ according to a state-specific duration distribution, and sample the
latent state sequence using a message passing algorithm suited for
HSMMs \cite{johnson2013bayesian}.  Inference for the $\bphi$ matrix
is not affected, since the diagonal elements are assumed to be 1.
Unlike in the original representation of the HDP-HSMM, no further
data-augmentation is needed, as the (continuous) durations $\bu$ already
account for the normalization of the $\bpi$.

\subsection{An Infinite Factorial HDP-HMM-LT}

One setting in which a local transition property is
desireable is the case where the latent states indicate which in a set
of hidden features is ``active'' at time $t$; that is, when the latent
state is represented by a binary vector.  A parametric example of such
a model is the Factorial HMM \cite{ghahramani1997factorial},
nonparametric extensions of which, such as the infinite factorial
hidden Markov Model \cite{gael2009infinite} and the infinite factorial dynamic model
\cite{valera2015infinite}, have been developed in recent years
by making use of the Indian Buffet Process
\cite{ghahramani2005infinite} as a state prior.  It would be
conceptually straightforward to combine the IBP state prior with the
similarity bias of the LT model, provided the chosen similarity
function is uniformly bounded above on the space of infinite length
binary vectors (for example, take $\phi(u,v)$ to be the exponentiated
negative Hamming distance between $u$ and $v$).  Since the number of
differences between two draws from the IBP is finite with probability
1, this yields a reasonable similarity metric.


% \subsection{Summary}
% \label{sec:model-summary}

% We have defined the following augmented generative model for the
% HDP-H(S)MM-LT:
% \begin{align}
%   \label{eq:96}
%   \bbeta &\sim \mathrm{GEM}(\gamma) \\
%   \theta_j &\stackrel{i.i.d}{\sim} H \\
%   \pi_{jj'} \given \bbeta, \btheta &\sim \Gamm{\alpha \beta_{j'}}{1}
%   \\
%   z_{t} \given z_{t-1}, \bpi, \btheta &\sim \sum_{j}
%   \left(\frac{\pi_{z_{t-1}j}\phi_{z_{t-1}j}}{\sum_{j'}
%     \pi_{z_{t-1}j'}\phi_{z_{t-1}j'}}\right)\delta_j \\
%   u_j \given \bz, \bpi, \btheta &\stackrel{ind}{\sim}
%   \Gamm{n_{j\cdot}}{\sum_{j'} \pi_{jj'}\phi_{jj'}} \\
%   q_{jj'} \given \bu, \bpi, \btheta &\stackrel{ind}{\sim}
%   \Pois{u_j(1 - \phi_{jj'})\pi_{jj'}} \\
%   \label{eq:likelihood} \by_t \given \bz, \btheta &\sim F(\theta_{z_t})
% \end{align}

% If we are using the HSMM variant, then we simply fix $\pi_{jj}$ to 0
% for each $j$, draw
% \begin{align}
%   \label{eq:97}
%   \omega_j &\stackrel{i.i.d}{\sim} G \\
%   D_t \given \bz &\stackrel{ind}{\sim} g(\omega_{z_t}),
% \end{align}
% set
% \begin{equation}
%   \label{eq:98}
%   z^*_s = z_{\max\{T \given s \leq \sum_{t=1}^T D_t\}}
% \end{equation}
% and replace \eqref{eq:likelihood} with
% \begin{equation}
%   \label{eq:likelihood-hsmm} \by_s \given \bz, \btheta \sim F(\theta_{z^*_s})
% \end{equation}


% \section{An HDP-HMM With Local Transitions}

% The goal is to add to the transition model the concept of a transition to
% a ``nearby'' state, where nearness of $j$ and $j'$ is possibly a function of
% $\theta_j$ and $\theta_{j'}$.  In order to accomplish this, we first
% consider an alternative construction of the transition distributions,
% based on the Normalized Gamma Process representation of the Dirichlet
% Process \cite{ferguson1973bayesian}.

% \subsection{A Normalized Gamma Process representation of the HDP-HMM}
% \label{sec:normalized-gamma}

% Define a random measure, $\mu = \sum_{j=1}^{\infty} \pi_j \delta_{\theta_j}$, where 
% \begin{align}
%   \pi_j &\stackrel{ind}{\sim} \Gamm{w_j}{1} \label{eq:17}\\
%   T &= \sum_{j=1}^{\infty} \pi_j \label{eq:18}\\
%   \tilde{\pi}_j &= \frac{\pi_j}{T}   \label{eq:16}\\
%   \theta_j &\stackrel{i.i.d}{\sim} H \label{eq:19}
% \end{align}
% and subject to the constraint that $\sum_{j\geq 1} w_j < \infty$,
% which ensures that $T < \infty$ almost surely.  As
% shown by Paisley et al. (2011), for fixed $\{w_j\}$ and $\{\theta_j\}$, $\mu$ is distributed as a Dirichlet
% Process with base measure $\bw = \sum_{j=1}^{\infty} w_j \delta_{\theta_j}$.
% If we draw $\bbeta$ from a stick-breaking process and then draw a
% series $\{\mu_m\}_{m=1}^M$ of
% i.i.d. random measures from the above process, setting $\bw =
% \alpha\bbeta$ for some $\alpha > 0$, then
% this defines a Hierarchical Dirichlet Process.  If, moreover, there is
% one $\mu_m$ associated with every state $j$, then we obtain the
% HDP-HMM.

% We can thus write
% \begin{align}
%   \bbeta &\sim \mathsf{GEM}(\gamma)   \label{eq:20} \\
%   \theta_j &\stackrel{i.i.d.}{\sim} H \label{eq:21}\\
%   \pi_{jj'} &\stackrel{ind}{\sim} \Gamm{\alpha \beta_{j'}}{1} \label{eq:22}\\
%   T_j &= \sum_{j'=1}^{\infty} \pi_{jj'} \\
%   \tilde{\pi}_{jj'} &= \frac{\pi_{jj'}}{T_j} \label{eq:23},
% \end{align}
% where $\gamma$ and $\alpha$ are prior concentration hyperparameters
% for the two DP levels, where
% \begin{align}
%   \label{eq:50}
%   p(z_t \given z_{t-1}, \bpi) = \tilde{\pi}_{z_{t-1}z_t}
% \end{align}
% and the observed data
% $\{y_t\}_{t\geq 1}$ distributed as
% \begin{equation}
%   \label{eq:24}
%   y_t \given z_t \stackrel{ind}{\sim} F(\theta_{z_t})
% \end{equation}
% for some family, $F$ of probability measures indexed by values of $\theta$.

% \subsection{Promoting ``Local" Transitions}
% \label{sec:prom-local-trans}

% In the preceding formulation, the $\theta_j$ and the $\pi_{jj'}$ are independent
% conditioned on the top-level measure.  Our goal is to relax this
% assumption, in order to allow for prior knowledge
% that certain ``locations'', $\theta_j$, are more likely than others to
% produce large weights.  This can be accomplished by letting the rate
% parameter in the distribution of the $\pi_{jj'}$
% be a function of $\theta_j$ and $\theta_{j'}$.  
% Let $\Phi: \Omega \times \Omega \to [0,\infty)$ represent a
% ``similarity function'', and define a collection of random variables
% $\{\phi_{jj'}\}_{j,j' \geq 1}$ according to
% \begin{equation}
%   \phi_{jj'} = \phi(\theta_j, \theta_j')
% \end{equation}
% We can then generalize \eqref{eq:20}-\eqref{eq:23} to
% \begin{align}
%   \bbeta &\sim \mathrm{GEM}(\gamma) \\
%   \theta_j &\stackrel{i.i.d}{\sim} H \\
%   \pi_{jj'} \given \bbeta, \btheta &\sim \Gamm{\alpha \beta_{j'}}{\phi_{jj'}^{-1}} \\
%   T_j &= \sum_{j'=1}^{\infty} \pi_{jj'} \\
%   \tilde{\pi}_{jj'} &= \frac{\pi_{jj'}}{T_j}
% \end{align}
% so that the expected value of $\pi_{jj'}$ is
% $\alpha\beta_{j'}\phi_{jj'}$.  Since a similarity between one object
% and another should not exceed the similarity between an object and
% itself, we will assume that $\phi_{jj'} \leq B < \infty$ for all $j$
% and $j'$, with equality holding iff $j = j'$.  Moreover, there 
% is no loss of generality by taking $B = 1$, since a constant rescaling of
% $\phi_{jj'}$ gets absorbed in the normalization.

% The above model is equivalent to simply drawing the $\pi_{jj'}$ as in
% \eqref{eq:20} and scaling each one by $\phi_{jj'}$ prior to
% normalization.

% Unfortunately, this formulation complicates inference significantly,
% as the introduction of non-constant rate parameters to the prior on
% $\bpi$ destroys the conjugacy between $\bpi$ and $\bz$, and worse, the
% conditional likelihood function for $\bpi$ contains an infinite
% sum of the elements in a row, rendering all entries within a row
% mutually dependent.

% \subsection{The HDP-HMM-LT as a continuous-time 
% Markov Jump Process with ``failed'' jumps}
% \label{sec:dist-based-filt}

% We can gain stronger intuition, as well as simplify posterior
% inference, by re-casting the HDP-HMM-LT described in the last section
% as a continuous time Markov Jump Process where some of the attempts to jump
% from one state to another fail, and where the failure probability
% increases as a function of the ``distance'' between the states.

% Let $\Phi$ be defined as in the last section, and let 
% $\bbeta$, $\btheta$ and $\bpi$ be defined as in the Normalized Gamma
% Process representation of the ordinary HDP-HMM.  That is,
% \begin{align}
%   \label{eq:beta} \bbeta &\sim \mathrm{GEM}(\gamma) \\
%   \theta_j &\stackrel{i.i.d}{\sim} H \\
%   \pi_{jj'} \given \bbeta, \btheta &\sim \Gamm{\alpha \beta_{j'}}{1}
% \end{align}
% Now suppose that when the process is in state $j$, jumps to state
% $j'$ are made at rate $\pi_{jj'}$.  This defines a continuous-time
% Markov Process where the off-diagonal elements of the transition rate
% matrix are the off diagonal elements of $\bpi$.  In addition,
% self-jumps are allowed, and occur with rate $\pi_{jj}$.   If we only
% observe the jumps and not the durations between jumps, this is an
% ordinary Markov chain, whose transition matrix is obtained by
% appropriately normalizing $\bpi$.  If we do not observe the jumps themselves, but
% instead an observation is generated once per jump from a distribution that depends
% on the state being jumped to, then we have an ordinary HMM.

% I modify this process as follows.  
% Suppose that each jump attempt from state $j$ to state $j'$ has a
% chance of failing, which is an increasing function of the ``distance''
% between the states.  In particular, let the success probability be
% $\phi_{jj'}$ (recall that we assumed above that $0 \leq \phi_{jj'}
% \leq 1$ for all $j,j'$).  Then, the rate of successful jumps from $j$
% to $j'$ is $\pi_{jj'}\phi_{jj'}$, and the corresponding rate of unsuccessful jump
% attempts is $\pi_{jj'}(1-\phi_{jj'})$.  To see this, denote by
% $N_{jj'}$ the total number of jump attempts to $j'$ in a unit
% interval of time spent in state $j$.  Since we are assuming the
% process is Markovian, the total number of attempts is $\Pois{\pi_{jj'}}$
% distributed.  Conditioned on $N_{jj'}$, $n_{jj'}$ will be successful, where
% \begin{equation}
%   \label{eq:51}
%   n_{jj'} \given N_{jj'} \sim \Binom{N_{jj'}}{\phi_{jj'}}
% \end{equation}
% It is easy to show (and well known) that the marginal distribution of
% $n_{jj'}$ is $\Pois{\pi_{jj'}\phi_{jj'}}$, and the marginal
% distribution of $\tilde{q}_{jj'} := N_{jj'} - n_{jj'}$ is
% $\Pois{\pi_{jj'}(1-\phi_{jj'})}$.  The rate of successful jumps
% from state $j$ overall is then $T_j := \sum_{j'} \pi_{jj'} \phi_{jj'}$.

% Let $t$ index jumps, so that $z_t$ indicates the $t$th state visited
% by the process (couting self-jumps as a new time step).  Given
% that the process is in state $j$ at discretized time $t-1$ (that is,
% $z_{t-1} = j$), it is a standard property of Markov Processes that 
% the probability that the first successful jump is to state $j'$ (that is, $z_{t} = j'$) 
% is proportional to the rate of successful attempts to 
% $j'$, which is $\pi_{jj'}\phi_{jj'}$.  

% Let $\tau_{t}$ indicate the time elapsed between the $t$th and 
% and $t-1$th successful jump (where we assume that the first
% observation occurs when the first successful jump from a distinguished initial
% state is made).  We have
% \begin{equation}
%   \label{eq:52}
%   \tau_t \given z_{t-1} \sim \Exp{T_{z_{t-1}}}
% \end{equation}
% where $\tau_t$ is independent of $z_{t}$.

% During this period, there will be $\tilde{q}_{j't}$ unsuccessful attempts to
% jump to state $j'$, where
% \begin{equation}
%   \label{eq:53}
%   \tilde{q}_{j't} \given z_{t-1} \sim \Pois{\tau_t \pi_{z_{t-1}j'}(1-\phi_{z_{t-1}j'})}
% \end{equation}

% Define the following additional variables
% \begin{align}
%   \label{eq:56}
%     \mathcal{T}_j &= \{t \given z_{t-1} = j\} \\
%     q_{jj'} &= \sum_{t \in \mathcal{T}_j}
%     \tilde{q}_{j't} \\
%     u_j &= \sum_{t \in \mathcal{T}_j} \tau_t 
% \end{align}
% and let $\bQ = (q_{jj'})_{j,j' \geq 1}$ be the matrix of unsuccessful
% jump attempt counts, and $\bu = (u_j)_{j \geq 1}$ be the vector of
% the total times spent in each state.

% Since each of the $\tau_t$ with $t \in \mathcal{T}_j$ are
% i.i.d. $\Exp{T_j}$, we get the marginal distribution
% \begin{equation}
% u_j \given \bz, \bpi \btheta \stackrel{ind}{\sim} \Gamm{n_{j\cdot}}{T_j}
% \end{equation}
% by the standard property that sums of i.i.d. Exponential distributions
% has a Gamma distribution with shape equal to the number of variates in
% the sum, and rate equal to the rate of the individual exponentials.  
% Moreover, since the $\tilde{q}_{j't}$ with $t \in \mathcal{T}_j$ 
% are Poisson distributed, the total number of failed
% attempts in the total duration $u_j$ is
% \begin{equation}
%   \label{eq:60}
%   q_{jj'} \stackrel{ind}{\sim} \Pois{u_j\pi_{jj'}(1-\phi_{jj'})}.
% \end{equation}

% Thus if we marginalize out the individual $\tau_t$ and
% $\tilde{q}_{j't}$, we have a joint distribution
% over $\bz$, $\bu$, and $\bQ$, conditioned on the transition rate
% matrix $\bpi$ and the success probability matrix $\bphi$, which is
% \begin{align}
%   \label{eq:54}
%   p(\bz, \bu, \bQ \given \bpi, \btheta) &= \left(\prod_{t=1}^T p(z_{t} \given
%     z_{t-1})\right) \prod_{j} p(u_j \given \bz, \bpi, \btheta)
%   \prod_{j'} p(q_{jj'} \given u_j \pi_{jj'}, \phi_{jj'}) \\
%   &= \left(\prod_{t} \frac{\pi_{z_{t-1}z_t}\phi_{z_{t-1}z_t}}{T_{z_{t-1}}}\right) \prod_{j}
%   \frac{T_j^{n_{j\cdot}}}{\Gamma(n_{j\cdot})} u_j^{n_{j\cdot} - 1}
%   e^{-T_j u_j} \\ &\qquad\qquad\times
%   \prod_{j'} e^{-u_j\pi_{jj'}(1-\phi_{jj'})} u_j^{q_{jj'}}
%   \pi_{jj'}^{q_{jj'}} (1-\phi_{jj'})^{q_{jj'}} (q_{jj'}!)^{-1} \\
%   &= \prod_{j} \Gamma(n_{j\cdot})^{-1} u_j^{n_{j\cdot} + q_{j\cdot}-1}
%   \\ &\qquad\qquad \times \prod_{j'}
%   \pi_{jj'}^{n_{jj'} + q_{jj'}} \phi_{jj'}^{n_{jj'}}
%   (1-\phi_{jj'})^{q_{jj'}} e^{-\pi_{jj'}\phi_{jj'}u_j}
%   e^{-\pi_{jj'}(1-\phi_{jj'})u_j} (q_{jj'}!)^{-1} \\
%   &\label{eq:joint-likelihood} = \prod_{j} \Gamma(n_{j\cdot})^{-1} u_j^{n_{j\cdot} + q_{j\cdot}-1} \prod_{j'}
%   \pi_{jj'}^{n_{jj'} + q_{jj'}} \phi_{jj'}^{n_{jj'}}
%   (1-\phi_{jj'})^{q_{jj'}} e^{-\pi_{jj'}u_j} (q_{jj'}!)^{-1}
% \end{align}

% \subsection{An HDP-HSMM-LT modification}
% \label{sec:an-hsmm-modification}

% Note that it is trivial to modify the HDP-HMM-LT to allow the
% number of observations generated each time a state is visited to have
% a distribution which is not Geometric, by simply fixing the diagonal
% elements of $\bpi$ to be zero, and allowing $D_t$ observations to be
% emitted $i.i.d.$ $F(\theta_{z_t})$ at jump $t$, where
% \begin{equation}
%   \label{eq:95}
%   D_t \given \bz \stackrel{ind}{\sim} g(\omega_{z_t}) \qquad \omega_j
%   \stackrel{i.i.d}{\sim} G
% \end{equation}
% The likelihood then includes the additional term for the $D_t$, and
% the only inference step which is affected is that instead of sampling
% $\bz$ alone, we sample $\bz$ and the $D_t$ jointly, by defining
% \begin{equation}
%   z^*_s = z_{\max\{T \given s \leq \sum_{t=1}^T D_t\}}
% \end{equation}
% where $s$ ranges over the number of observations, 
% and associating a $\by_s$ with each $z^*_s$.
% Inferences about $\bphi$ are not affected, since the diagonal
% elements are assumed to be 1 anyway.

% This is the same construction used in the Hierarchical Dirichlet
% Process Hidden Semi-Markov Model (HDP-HSMM;
% \cite{johnson2013bayesian}).  
% Unlike in the standard representation of the HDP-HSMM,
% however, there is no need to introduce
% additional auxiliary variables as a result of this modification, due
% to the presence of the (continuous) durations, $\bu$, which were
% already needed to account for the normalization of the $\bpi$.

% \subsection{Summary}
% \label{sec:model-summary}

% I have defined the following augmented generative model for the
% HDP-H(S)MM-LT:
% \begin{align}
%   \label{eq:96}
%   \bbeta &\sim \mathrm{GEM}(\gamma) \\
%   \theta_j &\stackrel{i.i.d}{\sim} H \\
%   \pi_{jj'} \given \bbeta, \btheta &\sim \Gamm{\alpha \beta_{j'}}{1}
%   \\
%   z_{t} \given z_{t-1}, \bpi, \btheta &\sim \sum_{j}
%   \left(\frac{\pi_{z_{t-1}j}\phi_{z_{t-1}j}}{\sum_{j'}
%     \pi_{z_{t-1}j'}\phi_{z_{t-1}j'}}\right)\delta_j \\
%   u_j \given \bz, \bpi, \btheta &\stackrel{ind}{\sim}
%   \Gamm{n_{j\cdot}}{\sum_{j'} \pi_{jj'}\phi_{jj'}} \\
%   q_{jj'} \given \bu, \bpi, \btheta &\stackrel{ind}{\sim}
%   \Pois{u_j(1 - \phi_{jj'})\pi_{jj'}} \\
%   \label{eq:likelihood} \by_t \given \bz, \btheta &\sim F(\theta_{z_t})
% \end{align}

% If we are using the HSMM variant, then we simply fix $\pi_{jj}$ to 0
% for each $j$, draw
% \begin{align}
%   \label{eq:97}
%   \omega_j &\stackrel{i.i.d}{\sim} G \\
%   D_t \given \bz &\stackrel{ind}{\sim} g(\omega_{z_t}),
% \end{align}
% for chosen $G$ and $g$, set
% \begin{equation}
%   \label{eq:98}
%   z^*_s = z_{\max\{T \given s \leq \sum_{t=1}^T D_t\}}
% \end{equation}
% and replace \eqref{eq:likelihood} with
% \begin{equation}
%   \label{eq:likelihood-hsmm} \by_s \given \bz, \btheta \sim F(\theta_{z^*_s})
% \end{equation}
